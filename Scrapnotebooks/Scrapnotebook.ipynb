{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:05:38.010997Z",
     "start_time": "2021-01-04T02:05:38.008962Z"
    }
   },
   "outputs": [],
   "source": [
    "# # define dataset\n",
    "# X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "#     n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "# # summarize class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)\n",
    "\n",
    "# # transform the dataset\n",
    "# oversample = SMOTE()\n",
    "# X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "# # summarize the new class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)\n",
    "\n",
    "# # scatter plot of examples by class label\n",
    "# for label, _ in counter.items():\n",
    "#     row_ix = where(y == label)[0]\n",
    "#     pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:05:53.917900Z",
     "start_time": "2021-01-04T02:05:53.915407Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Oversample with SMOTE and random undersample for imbalanced dataset\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# # define dataset\n",
    "# X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "#     n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "# # summarize class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)\n",
    "\n",
    "# # define pipeline\n",
    "# over = SMOTE(sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# # transform the dataset\n",
    "# X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "# # summarize the new class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)\n",
    "\n",
    "# # scatter plot of examples by class label\n",
    "# for label, _ in counter.items():\n",
    "#     row_ix = where(y == label)[0]\n",
    "#     pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:06:07.799640Z",
     "start_time": "2021-01-04T02:06:07.797518Z"
    }
   },
   "outputs": [],
   "source": [
    "# build model with SMOTE imblearn\n",
    "# smote_pipeline = make_pipeline_imb(SMOTE(random_state=4), classifier(random_state=42))\n",
    "# smote_model = smote_pipeline.fit(X_train, y_train)\n",
    "# smote_prediction = smote_model.predict(X_test)\n",
    "\n",
    "# # build model with undersampling\n",
    "# nearmiss_pipeline = make_pipeline_imb(NearMiss(random_state=42), classifier(random_state=42))\n",
    "# nearmiss_model = nearmiss_pipeline.fit(X_train, y_train)\n",
    "# nearmiss_prediction = nearmiss_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:06:18.003652Z",
     "start_time": "2021-01-04T02:06:18.001587Z"
    }
   },
   "outputs": [],
   "source": [
    "# # printing information about both models\n",
    "# print()\n",
    "# print('normal data distribution: {}'.format(Counter(df['target'])))\n",
    "# X-smote, y_smote = SMOTE().fit_sample(df['df'], df['target'])\n",
    "# print('SMOTE data distribution: {}'.format(Counter(y_smote)))\n",
    "# X_nearmiss, y_nearmiss = NearMiss().fitsample(df['df'], df['target'])\n",
    "# print('NearMiss data distribution: {}'.format(Counter(y_nearmiss)))\n",
    "\n",
    "# # Classification report\n",
    "# print(classification_report(y_test, prediction))\n",
    "# print(classification_report_imbalanced(y_test, smote_prediction))\n",
    "\n",
    "# print()\n",
    "# print('normal Pipeline Score {}'.format(pipeline.score(X_test, y_test)))\n",
    "# print('SMOTE Pipeline Score {}'.format(smote_pipeline.score(X_test, y_test)))\n",
    "# print('NearMiss Pipeline Score {}'.format(nearmiss_pipeline.score(X_test, y_test)))\n",
    "\n",
    "# print()\n",
    "# print_results('normal classification', y_test, prediction)\n",
    "# print()\n",
    "# print_results('SMOTE classification', y_test, smote_prediction)\n",
    "# print()\n",
    "# print_results('NearMiss classification', y_test, nearmiss_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:06:28.716020Z",
     "start_time": "2021-01-04T02:06:28.713361Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # cross validation done right\n",
    "# kf = KFold(n_splits=5, random_state=42)\n",
    "# accuracy = []\n",
    "# precision = []\n",
    "# recall = []\n",
    "# f1 = []\n",
    "# auc = []\n",
    "# for train, test in kf.split(X_train, y_train):\n",
    "#     pipeline = make_pipeline_imb(SMOTE(), classifier(random_state=42))\n",
    "#     model = pipeline.fit(X_train[train], y_train[train])\n",
    "#     prediction = model.predict(X_train[test])\n",
    "\n",
    "#     accuracy.append(pipeline.score(X_train[test], y_train[test]))\n",
    "#     precision.append(precision_score(y_train[test], prediction))\n",
    "#     recall.append(recall_score(y_train[test], prediction))\n",
    "#     f1.append(f1_score(y_train[test], prediction))\n",
    "#     auc.append(roc_auc_score(y_train[test], prediction))\n",
    "\n",
    "# print()\n",
    "# print(\"done right mean of scores 5-fold:\")\n",
    "# print(\"accuracy: {}\".format(np.mean(accuracy)))\n",
    "# print(\"precision: {}\".format(np.mean(precision)))\n",
    "# print(\"recall: {}\".format(np.mean(recall)))\n",
    "# print(\"f1: {}\".format(np.mean(f1)))\n",
    "# print()\n",
    "\n",
    "# # cross validation done wrong\n",
    "# kf = KFold(n_splits=5, random_state=42)\n",
    "# accuracy = []\n",
    "# precision = []\n",
    "# recall = []\n",
    "# f1 = []\n",
    "# auc = []\n",
    "# X, y = SMOTE().fit_sample(X_train, y_train)\n",
    "# for train, test in kf.split(X, y):\n",
    "#     pipeline = make_pipeline(classifier(random_state=42))\n",
    "#     model = pipeline.fit(X[train], y[train])\n",
    "#     prediction = model.predict(X[test])\n",
    "\n",
    "#     accuracy.append(pipeline.score(X[test], y[test]))\n",
    "#     precision.append(precision_score(y[test], prediction))\n",
    "#     recall.append(recall_score(y[test], prediction))\n",
    "#     f1.append(f1_score(y[test], prediction))\n",
    "\n",
    "# print(\"done wrong mean of scores 5-fold:\")\n",
    "# print(\"accuracy: {}\".format(np.mean(accuracy)))\n",
    "# print(\"precision: {}\".format(np.mean(precision)))\n",
    "# print(\"recall: {}\".format(np.mean(recall)))\n",
    "# print(\"f1: {}\".format(np.mean(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:37:13.087393Z",
     "start_time": "2021-01-04T02:37:13.079751Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.scatter(X, y, color='#003F72', label= 'Data points')\n",
    "# plt.plot(X, regression_line, label= 'Regression Line')\n",
    "# plt.xlabel('Sqft Living')\n",
    "# plt.ylabel('Price (Millions)')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:39:31.421258Z",
     "start_time": "2021-01-04T02:39:31.419282Z"
    }
   },
   "outputs": [],
   "source": [
    "# # classifier to use     (can I use def to imput all 4 models here?)\n",
    "# classifier = RandomForestClassifier\n",
    "\n",
    "# # splitting data into trainning and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state=1)\n",
    "\n",
    "# # building normal model\n",
    "# pipeline = make_pipeline(classifier(random_state=42))\n",
    "# model = pipeline.fit(X_train, y_train)\n",
    "# prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:39:44.054846Z",
     "start_time": "2021-01-04T02:39:44.052611Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import TransformerMixin\n",
    "\n",
    "# class ForestEncoder(TransformerMixin):\n",
    "    \n",
    "#     def __init__(self, forest):\n",
    "#         self.forest = forest\n",
    "#         self.n_trees = 1\n",
    "#         try:\n",
    "#             self.n_trees = self.forest.n_estimators\n",
    "#         except:\n",
    "#             pass\n",
    "#         self.ohe = OneHotEncoder(cols=range(self.n_trees), use_cat_names=True)\n",
    "        \n",
    "#     def fit(self, X, y=None):\n",
    "#         self.forest.fit(X, y)\n",
    "#         self.ohe.fit(self.forest.apply(X))\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         return self.ohe.transform(self.forest.apply(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T02:39:53.427644Z",
     "start_time": "2021-01-04T02:39:53.425839Z"
    }
   },
   "outputs": [],
   "source": [
    "# N = 5\n",
    "\n",
    "# rf = RandomForestClassifier(max_depth = N, n_estimators=100, n_jobs=-1, \n",
    "#                             random_state=42,criterion = 'entropy', max_leaf_nodes = 2**N-1)\n",
    "# encoder = ForestEncoder(rf)\n",
    "# clf = LogisticRegression(class_weight='balanced')\n",
    "# pipe = make_pipeline(encoder, clf)\n",
    "# pipe.fit(X, y)\n",
    "\n",
    "# scores = cross_val_score(rf, X, y, cv=5, scoring='roc_auc')\n",
    "# print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
